# Job
**For tasks that need to be executed only once, such as database migrations, file processing, or sending batch emails.**
A **Job** is one of the workload types in Kubernetes used for running tasks or short-lived operations. Unlike **Deployment** or **DaemonSet**, which are designed for long-running applications, a **Job** is used for tasks that terminate automatically after completion.

---

## What is a Job Used For?
Imagine you have tasks that need to run only once or a specific number of times, such as:
- **Batch Processing**: For example, processing data from a file or database.
- **Running Scripts**: Like executing a script to apply specific configurations in your infrastructure.
- **Temporary Changes**: Such as restarting a specific service or cleaning up old logs.
- **Data Collection**: For example, taking a database backup or generating daily reports.

---

## How Does It Work?
A Job creates one or more Pods, and these Pods perform the specified task. When all Pods complete their tasks successfully, the Job is considered **Complete**. If a Pod fails or doesn’t complete its task, the Job automatically creates a new Pod to continue the work.

---

## Key Components of a Job
### 1. RestartPolicy
This determines how Kubernetes should behave when a Pod fails or crashes.
- **RestartPolicy = Never**: If a Pod fails, Kubernetes does not restart it. Instead, it creates a new Pod.
- **RestartPolicy = OnFailure**: If a Pod fails, Kubernetes restarts the same Pod.

### 2. Completions and Parallelism
- **Completions**: The number of times the Job must be successfully executed. For example, if `completions: 3`, the Job must succeed 3 times to be considered complete.
- **Parallelism**: The number of Pods that can run simultaneously. For example, if `parallelism: 2`, two Pods will run concurrently.

### 3. Active Deadline Seconds
This sets a time limit for the Job. If the Job does not complete within this time, Kubernetes stops it.

### 4. Backoff Limit
The number of times Kubernetes will attempt to retry a Job in case of failure. For example, if `backoffLimit: 4`, Kubernetes will stop the Job after 4 unsuccessful attempts.

---

## Practical Example of a Job

### Scenario:
Suppose you want to create a Job that runs a simple Bash script and prints a message.

### YAML File:
```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: hello-job
spec:
  completions: 3
  parallelism: 2
  backoffLimit: 4
  activeDeadlineSeconds: 60
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: hello
        image: busybox
        command: ["echo", "Hello, Kubernetes!"]
```

### Explanation of the YAML File:
* `kind`: Job: Specifies that this workload is a Job.

* `completions`: 3: The Job must succeed 3 times.
* `parallelism`: 2: A maximum of 2 Pods can run simultaneously.
* `backoffLimit`: 4: If a Pod fails, Kubernetes will retry the Job up to 4 times.
* `activeDeadlineSeconds`: 60: If the Job does not complete within 60 seconds, Kubernetes will stop it.
* `restartPolicy`: Never: If a Pod fails, Kubernetes will not restart it and will create a new Pod instead.
* `containers`: A container using the busybox image that prints the message: Hello, Kubernetes!.

## Summary
* Job is ideal for running short-lived tasks or batch operations.
* It ensures that tasks are completed successfully, even if Pods fail.
* You can control the number of completions, parallelism, retries, and time limits for a Job.

---

# Cleaning Up Pods in Kubernetes Jobs
In Kubernetes, when a Job is executed, the Pods created by the Job remain in the cluster after they finish their tasks (whether they succeed or fail). This means the Pods are not deleted and can still be seen in the following states:
- **Completed**: If the Pod successfully completed its task.
- **Failed**: If the Pod failed for any reason.
This behavior is designed to allow you to review execution history (logs, statuses, and outputs). However, it can lead to some issues:

---

## Why is Cleaning Up Pods Important?
1. **Accumulation of Old Pods (Resource Usage)**:
   - When old Pods are not deleted, a large number of Pods in the `Completed` or `Failed` state accumulate in the cluster.
   - This unnecessarily consumes storage space and management resources like ETCD.
2. **Reduced Cluster Readability and Management**:
   - The presence of many old Pods makes it harder to find active or running Pods.
   - For operations teams, it can be time-consuming to manually review and delete old Pods.
3. **Resource Limitations in the Cluster**:
   - Every Pod in the cluster (even in the `Completed` state) still consumes management resources. Excessive accumulation of such Pods can reduce cluster efficiency.

---

## How to Solve This Problem?
Kubernetes provides several solutions to address this issue, depending on your needs:

### 1. TTL for Jobs (TTL Controller)
Starting from Kubernetes v1.21, the **TTL Controller** feature was introduced. This feature allows Pods associated with a Job to be automatically deleted after the Job completes (whether successfully or unsuccessfully).
- **TTL (Time To Live)**: The amount of time Pods remain in the cluster after the Job finishes.

#### How to Configure TTL?
You can set the `ttlSecondsAfterFinished` field in the Job manifest. For example:
```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: hello-job
spec:
  ttlSecondsAfterFinished: 30
  template:
    spec:
      containers:
      - name: hello
        image: busybox
        command: ["echo", "Hello, Kubernetes!"]
      restartPolicy: Never
```
#### Explanation:
- `ttlSecondsAfterFinished: 30`: This means that 30 seconds after the Job reaches the `Completed` or `Failed` state, the Pods and Job will be automatically deleted.

### 2. Manually Deleting Jobs and Pods
If you have Jobs without TTL configured or need to clean them up manually, you can use the following commands:

Delete a Job:
```bash
kubectl delete job <job-name>
```
Delete Pods Associated with a Job:
```bash
kubectl delete pod -l job-name=<job-name>
```
#### Explanation:
- Deleting a Job does not automatically delete its associated Pods unless TTL is configured.
- The second command allows you to delete Pods associated with a specific Job.

### 3. Using CronJob for Periodic Cleanup
If you have many Jobs and don’t want to manage them manually or with TTL, you can create a CronJob to periodically clean up old Pods.

### 4. Configuring TTL Controller for the Entire Cluster
If you want the TTL Controller to be enabled by default for all Jobs in the cluster, you can activate this feature in the cluster settings. This requires access to the API Server configuration.

```bash
kubectl get job
```
```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: throw-dice-job
spec:
  completions: 3
  parallelism: 3
  backoffLimit: 25 # This is so the job does not quit before it succeeds.
  template:
    spec:
      containers:
      - name: throw-dice
        image: kodekloud/throw-dice
      restartPolicy: Never # Does not automatically restart the terminated container.
```

---

# CronJob
**For tasks that need to be executed regularly or at specific times, such as regular backups, service status monitoring, or sending periodic reports.**
**CronJob** is one of the workload types in Kubernetes used for scheduling Jobs at specific times. If you have experience with `cron` in Linux, CronJob works similarly but within the Kubernetes ecosystem, leveraging Kubernetes' capabilities. CronJob is designed for tasks like scheduled processing, routine email sending, database backups, or running automated scripts. It overcomes the limitations of regular Jobs and allows you to manage Jobs with precise scheduling.

---

## What Problems Does CronJob Solve?

Before CronJob, if you wanted to run Jobs on a schedule, you had to design a separate mechanism or use external tools. CronJob solves this issue entirely and provides the following features:

1. **Precise Scheduling**:
   - CronJob allows you to specify the execution time using the cron format.
   - For example, daily, weekly, or even every minute.
2. **Control Over Old Jobs**:
   - You can define how many successful or failed Jobs are stored in the history.
3. **Automatic Job Management**:
   - You don’t need to manually handle Job reruns or manage old Jobs. Kubernetes handles this automatically.
4. **Native Kubernetes Integration**:
   - Job execution and management are handled natively within Kubernetes, eliminating the need for external tools.

---

## Important Note: CronJob Time Must Align with Kube Controller Manager
When configuring the CronJob schedule, you must ensure that the time zone of the Kubernetes server (i.e., `kube-controller-manager`) matches the time zone you set for the CronJob. If these are not aligned, the CronJob may run at the wrong time.

---

## Interval in CronJob
The interval or time schedule in CronJob is defined using the cron format. The cron format consists of 5 main fields:
```bash
* * * * *
- - - - -
| | | | |
| | | | +----- Day of Week (0 - 7) (0 or 7 = Sunday)
| | | +------- Month (1 - 12)
| | +--------- Day of Month (1 - 31)
| +----------- Hour (0 - 23)
+------------- Minute (0 - 59)
```
### Examples:
- `*/5 * * * *`: Runs every 5 minutes.
- `0 0 * * *`: Runs every day at midnight.
- `0 0 1 * *`: Runs on the first day of every month at midnight.

---

## History in CronJob
Kubernetes allows you to limit the number of successful and failed Jobs stored in the history. This is done using the following fields:
1. **`.spec.successfulJobsHistoryLimit`**:
   - The number of successfully completed Jobs to keep in history.
   - Default value: `3`.
2. **`.spec.failedJobsHistoryLimit`**:
   - The number of failed Jobs to keep in history.
   - Default value: `1`.
You can adjust these values in the CronJob definition.

---

## Where is CronJob Useful?
- **Taking Backups**: Take a database backup every night at midnight.
- **Cleaning Old Logs**: Delete old logs once a week.
- **Sending Reports**: Send a system status report every morning.
- **System Checks**: Run a script every 10 minutes to check the system status.

---

## Summary
- **CronJob** is ideal for running scheduled tasks in Kubernetes.
- It provides precise scheduling, automatic Job management, and native Kubernetes integration.
- You can control the history of successful and failed Jobs to keep your cluster clean and efficient.

```bash
kubectl get cronjob
```
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: throw-dice-cron-job
spec:
  schedule: "30 21 * * *"
  jobTemplate:
    spec:
      completions: 3
      parallelism: 3
      backoffLimit: 25 # This is so the job does not quit before it succeeds.
      template:
        spec:
          containers:
          - name: throw-dice
            image: kodekloud/throw-dice
          restartPolicy: Never
```
**Using these resources helps you manage various processes automatically and with proper scheduling.**

Another Ex:
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: dice
spec:
  schedule: "*/1 * * * *"  # runs every one minute
  jobTemplate:
    spec:
      completions: 1
      backoffLimit: 25 # This is so the job does not quit before it succeeds.
      activeDeadlineSeconds: 20 # If the task is not completed within 20 seconds the job will be fail and pods will be terminated.
      template:
        spec:
          containers:
          - name: dice
            image: kodekloud/throw-dice
          restartPolicy: Never
```
