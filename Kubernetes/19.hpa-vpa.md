# Horizontal Scaling & Horizontal Pod Autoscaler (HPA)
#### Automatically scales Pods horizontally based on resource usage.
#### Adjusts CPU and memory resources for Pods dynamically.
```bash
kubectl join ...
kubectl scale ...
kubectl edit ...
kubectl autoscale deployment nginx-deployment --max=3 --cpu-percent=80
```
Or user the yaml file:
```bash
nano autoscale.yml
```
```yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  creationTimestamp: null
  name: nginx-deployment
spec:
  maxReplicas: 3
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-deployment
  targetCPUUtilizationPercentage: 80
status:
  currentReplicas: 0
  desiredReplicas: 0
```
```bash
kubectl apply -f autoscale.yml
```
```bash
kubectl get hpa
kubectl describe hpa <deployment-name>
kubectl describe hpa nginx-deployment
kubectl events hpa nginx-deployment | grep -i "ScalingReplicaSet"
kubectl events hpa nginx-deployment | grep -i "FailedGetResourceMetric"
```
Another Ex:
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: webapp-hpa
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: kkapp-deploy
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 50
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        - type: Percent
          value: 10
          periodSeconds: 60
```
## Explanation of HPA File

- **scaleTargetRef**: This section specifies which Deployment the HPA will target. In this example, `kkapp-deploy` is the target of the HPA.
- **minReplicas and maxReplicas**:
  - `minReplicas`: The minimum number of Pods that should always be running (here, 2).
  - `maxReplicas`: The maximum number of Pods that Kubernetes can create (here, 10).
- **metrics**: Here, we define the criteria based on which the HPA should perform scaling.
  - `type: Resource`: This means that resources like CPU or Memory will be used for decision-making.
  - `averageUtilization`: The goal is that if the average CPU usage exceeds 50%, Kubernetes will increase the number of Pods.

**The `behavior` section in the Horizontal Pod Autoscaler (HPA) file** allows you to control scaling behavior (increasing or decreasing the number of Pods) more precisely. This section includes settings that specify how and how fast to scale up (increase) and scale down (decrease). In this example, only the `scaleDown` section is configured.
**Description of the `behavior` section:**
**`scaleDown`:**
* This section relates to settings for decreasing the number of Pods (scale down).
**`stabilizationWindowSeconds`:**
* This value (here, 300 seconds or 5 minutes) creates a "stabilization window." This means that the HPA waits 5 minutes before deciding to reduce Pods to ensure that the resource reduction is real and not due to short-term fluctuations.
**`policies`:**
* This section contains policies that specify how Pods are reduced.
    * `type: Percent`: This policy operates based on a percentage of the current Pods.
    * `value: 10`: At each step, a maximum of 10% of the current Pods are reduced.
    * `periodSeconds: 60`: This reduction occurs every 60 seconds.
**Summary:**
* **`stabilizationWindowSeconds`:** The HPA waits 5 minutes before reducing Pods to ensure the stability of the resource reduction.
* **`policies`:** The HPA reduces a maximum of 10% of the current Pods every 60 seconds at each step.
These settings help you prevent sudden and excessive Pod reduction and ensure that resource reduction occurs slowly and steadily.

**Important Points:**
* **Setting Resources in Deployment:** Always specify `resources.requests` and `resources.limits` in your Deployment, as HPA makes decisions based on these values.
* **HPA Only for CPU and Memory:** By default, HPA works with CPU and Memory consumption. If you want to use other metrics (such as request count or latency), you need to use Custom Metrics.

**Summary**
* With HPA, you can automatically increase or decrease the number of Deployment Pods based on specified metrics, such as CPU consumption.
* Set the minimum and maximum number of Pods using `minReplicas` and `maxReplicas`.
* Kubernetes always tries to maintain the status based on the target you set (such as 50% CPU consumption).
* **Scaling Time:** HPA does not work instantly. It usually takes a few minutes to apply changes because it needs to monitor the status.

---

# Vertical Pod Autoscaling (VPA)
```bash
git clone https://github.com/kubernetes/autoscaler.git
cd autoscaler/vertical-pod-autoscaler
./hack/vpa-up.sh
# To check the installed VPA CRDs
kubectl get crds | grep verticalpodautoscaler

kubectl get deployments -n kube-system | grep vpa 
# vpa-admission-controller, vpa-recommender, vpa-updater

kubectl get vpa
```
```yaml
apiVersion: "autoscaling.k8s.io/v1"
kind: VerticalPodAutoscaler
metadata:
  name: flask-app
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: flask-app-4
  updatePolicy:
    updateMode: "Off"  # You can set this to "Auto" if you want automatic updates
  resourcePolicy:
    containerPolicies:
      - containerName: '*'
        minAllowed:
          cpu: 100m
        maxAllowed:
          cpu: 1000m
        controlledResources: ["cpu"]
```
Another Ex:
```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: analytics-vpa
  namespace: default
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: analytics-deployment
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
      - containerName: "*"
        minAllowed:
          cpu: "100m"
          memory: "100Mi"
        maxAllowed:
          cpu: "2"
          memory: "4Gi"
```
