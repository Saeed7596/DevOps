# Service
#### Provides stable networking and communication between Pods.
```bash
kubectl get svc
kubectl get service
kubectl describe service
```
### Types of **Service** in Kubernetes

| Service Type    | Description | Common Usage |
|----------------|--------------------------------------------------|------------------------------|
| **ClusterIP**  | The default type, assigns an internal IP within the cluster, accessible only inside the cluster. | Internal communication between services within the cluster |
| **NodePort**   | Opens a port on each Node, allowing access from outside the cluster. | External access without a Load Balancer |
| **LoadBalancer** | Creates a public IP and a Load Balancer from the cloud provider. | Load distribution and direct external access |
| **ExternalName** | Maps requests to an external domain name (e.g., `example.com`). | Redirecting requests to external services |

---

# CoreDNS
When you create a Service in Kubernetes, a DNS record is automatically created by CoreDNS, which is the default DNS server used in most Kubernetes clusters.

## ðŸ” Here's how it works:
Kubernetes runs CoreDNS as a cluster add-on (a set of Pods in the kube-system namespace).

When a new Service is created, Kubernetes updates its internal API and DNS records.

CoreDNS monitors the Kubernetes API for changes and automatically creates corresponding DNS entries.

## ðŸ“Œ DNS Naming Format:
For a Service named my-service in namespace my-namespace, the DNS name is:

```pgsql
my-service.my-namespace.svc.cluster.local
```
So in short:

âœ… CoreDNS is responsible for automatically creating the DNS records for Services in Kubernetes.

---

# ClusterIP
In Kubernetes, when we want to create a service that should not be exposed externally (like Redis), we use the `ClusterIP` type service (which is the default type if not specified). 
> ClusterIP exposes the service only internally within the cluster and not to the outside world (unlike NodePort or LoadBalancer).

---

## Example YAML for a ClusterIP Service
```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-internal
  namespace: dev
spec:
  type: ClusterIP
  ports:
    - targetPort: 80
      port: 8080
  selector:
    app: nginx
```
## Notes on DNS in Kubernetes
* If it were the same inside the namespace, just the service name would be enough 
  - `http://nginx-internal:8080`
* To access a service from a different namespace, we should use the fully qualified domain name (FQDN) of the service.

Full Qualified Domain Name (FQDN) format:
```
<service-name>.<namespace>.svc.cluster.local
```
Example:
```pgsql
mysql.connect("db-service.dev.svc.cluster.local")
```

### Testing Internal Access to the Service using DNS
We can run a temporary pod (debugger) to test internal requests inside the cluster:
```bash
# Run a debug pod in the default namespace
kubectl -n default run debugger --image=alpine:3.11.3 --command -- sleep infinity

# Install curl inside the pod
kubectl -n default exec debugger -- apk add curl

# Access the nginx-internal service using DNS
kubectl -n default exec debugger -- curl http://nginx-internal.dev.svc.cluster.local:8080
```

---

# Headless Service
A Headless Service is a service without a ClusterIP. It is used mainly when you want to directly access individual Pods instead of load-balancing between them.

You can create a Headless Service by setting `clusterIP: None`.

Example:
```yaml
apiVersion: v1
kind: Service
metadata:
  name: mongo
  namespace: dev
spec:
  clusterIP: None     # Headless Service
  selector:
    app: mongo
  ports:
  - port: 27017
```
StatefulSet Example:
```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mongo
  namespace: dev
spec:
  serviceName: mongo  # important â†’ Headless Service Name
  replicas: 3
  selector:
    matchLabels:
      app: mongo
  template:
    metadata:
      labels:
        app: mongo
    spec:
      containers:
        - name: mongo
          image: mongo
          ports:
            - containerPort: 27017
```

### Use Case:
Headless Service is very useful for Stateful applications like MongoDB ReplicaSet, Cassandra, etc., where each Pod needs to be addressable individually.

DNS Records created for Headless Service:
```
mongo-0.mongo.dev.svc.cluster.local
mongo-1.mongo.dev.svc.cluster.local
mongo-2.mongo.dev.svc.cluster.local
```

---

# MongoDB ReplicaSet Architecture

![MongoDB ReplicaSet Architecture](https://www.mongodb.com/docs/manual/_images/replica-set-architecture.bakedsvg.svg)

### Components:
- Primary: Handles all writes
- Secondary: Syncs data from Primary (Read-only)
- Arbiter (Optional): Participates in election but doesn't store data

---

# Example MongoDB Connection String
```python
mongodb://mongo-0.mongo.dev.svc.cluster.local:27017,mongo-1.mongo.dev.svc.cluster.local:27017,mongo-2.mongo.dev.svc.cluster.local:27017/?replicaSet=rs0
```
This connection string ensures automatic detection of Primary and failover handling.

---

### Differences between **nodePort, port, and targetPort** in Kubernetes

| Parameter      | Description |
|---------------|--------------------------------------------------|
| **nodePort**  | The port opened on each Node, allowing external access (ranges between 30000-32767). |
| **port**      | The port defined in the Service that receives traffic. |
| **targetPort** | The port running inside the Pod that processes incoming requests. |

Example YAML configuration:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: example-service
spec:
  type: NodePort
  ports:
    - port: 80
      targetPort: 8080
      nodePort: 30080
```

In this example:
- Requests arrive at **port 80** on the Service.
- They are forwarded to **port 8080** inside the corresponding Pod.
- The Service is externally accessible on **port 30080** on each Node.

---

```bash
nano service-definition.yaml
kubectl apply -f service-definition.yaml
```
```yaml
apiVersion: v1
kind: Service
metadata:
  name: webapp-service
  namespace: default
spec:
  ports:
  - nodePort: 30080
    port: 8080
    targetPort: 8080
  selector:
    name: simple-webapp
  type: NodePort
```
```bash
kubectl run nginx --image=nginx --port=80 --expose # create a service for this pod

kubectl expose pod redis --port=6379 --name redis-service --dry-run=client -o yaml
kubectl create service clusterip redis --tcp=6379:6379 --dry-run=client -o yaml 
kubectl expose pod nginx --type=NodePort --port=80 --name=nginx-service --dry-run=client -o yaml
kubectl create service nodeport nginx --tcp=80:80 --node-port=30080 --dry-run=client -o yaml

kubectl run redis -l tier=db --image=redis:alpine # -l means Label
kubectl expose pod redis --port=6379 --target-port=6379 --name=redis-service --type=ClusterIP
```

```
# if messaging is deployment
kubectl expose deployment messaging --name=messaging-service --port=6379 --target-port=6379 --type=ClusterIP
# if messaging is pod
kubectl expose pod messaging --name=messaging-service --port=6379 --target-port=6379 --type=ClusterIP
```

---

### Communication Between Pods in Different Namespaces
- By default, Pods in different namespaces cannot directly discover each other. To establish communication, you must use the **full DNS name** of the service.

---

### Exposing Applications

There are several ways to expose applications in Kubernetes:

1. **NodePort**:
   - Exposes the service on a static port on each nodeâ€™s IP.
   - Accessible from outside the cluster using `<NodeIP>:<NodePort>`.

2. **LoadBalancer**:
   - Provisions an external load balancer (e.g., in cloud environments) to expose the service.
   - Automatically assigns an external IP.

3. **Ingress**:
   - Provides HTTP/HTTPS routing to services based on hostnames or paths.
   - Requires an Ingress controller to be installed in the cluster.

---

### How to Check if a Service is Pod-to-Pod
To determine if a service is Pod-to-Pod, you can check the following:

1. **Service Type**:
   - The service type should be `ClusterIP`.
   - Command:  
     ```bash
     kubectl get service <service-name> -n <namespace>
     ```

2. **Service Selector**:
   - The service selector should target internal Pods.

3. **Service Endpoints**:
   - The service endpoints should include the internal IPs of the Pods.
   - Command:  
     ```bash
     kubectl get endpoints <service-name> -n <namespace>
     ```

4. **DNS Testing from Inside a Pod**:
   - Access one of the Pods:  
     ```bash
     kubectl exec -it <pod-name> -n <namespace> -- /bin/bash
     ```
   - Send a request to the service:  
     ```bash
     curl http://<service-name>.<namespace>.svc.cluster.local
     ```
   - If the service is Pod-to-Pod, you should receive a response.

5. **Pod Logs**:
   - Check the logs of the Pods to verify internal communication:  
     ```bash
     kubectl logs <pod-name> -n <namespace>
     ```

---

### Multi-Port Service
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: multi-port-deployment
  labels:
    app: multi-port-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: multi-port-app
  template:
    metadata:
      labels:
        app: multi-port-app
    spec:
      containers:
      - name: multi-port-container
        image: nginx:stable
        ports:
        - containerPort: 80   # HTTP
        - containerPort: 443  # HTTPS
        - containerPort: 8080 # Custom Port
---
apiVersion: v1
kind: Service
metadata:
  name: multi-port-service
spec:
  selector:
    app: multi-port-app
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 80
  - name: https
    protocol: TCP
    port: 443
    targetPort: 443
  - name: custom-port
    protocol: TCP
    port: 8080
    targetPort: 8080
```

---

## LoadBalancer
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:stable
        ports:
        - containerPort: 80

---
apiVersion: v1
kind: Service
metadata:
  name: nginx-loadbalancer
spec:
  type: LoadBalancer
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80 # The input port of the service (LoadBalancer).
    targetPort: 80 # The port inside the Nginx container.
```
```bash
kubectl get services
```
In the browser or similar tools, enter the following address: `http://<EXTERNAL-IP>`

---

## ExternalName in Kubernetes
**ExternalName** is a type of Service in Kubernetes that, instead of connecting to Pods within the cluster, is used to redirect requests to an external service (outside the cluster). In simple terms, when clients access the service, Kubernetes redirects their requests to another domain name (DNS) that exists outside the cluster.

---

## When is ExternalName Useful?
- When an application inside the cluster needs to connect to a database or services outside the cluster, such as:
  - Connecting to a MySQL database running on another server.
  - Using an external API like Google Maps or any other API.
- When you want to simplify access to external services within the cluster.

### Example YAML for External Service:
```yaml
apiVersion: v1
kind: Service
metadata:
  name: mysql-external-service
spec:
  type: ExternalName
  externalName: mysql.external.com
```
### Example YAML for Internal Service:
```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  type: ExternalName
  externalName: my-service1.prod.svc.cluster.local
```
### Where is ExternalName Good and Where is it Not?
- Good For:
  - When you have a fixed external service with a DNS address.
  - When you want to simplify the naming of external services.

- Limitations:
  - ExternalName only works with services that have a DNS address. If the external service only has an IP, you cannot use ExternalName.
  - ExternalName does not perform load balancing. If the external service has multiple servers, Kubernetes will only connect to the specified DNS address.

#### Summary
ExternalName is a special type of Service in Kubernetes used to redirect requests to an external service (outside the cluster).
This type of service uses DNS to redirect requests.
It is mainly used for connecting to external services or simplifying access to external services within the cluster.

---

## External IPs in Kubernetes
When you have a service in Kubernetes that you want to access from outside the cluster (i.e., from an external network), you can use **External IPs**. In simple terms, External IP allows you to assign a specific IP to your service, and requests to that IP will be routed to the service.

## When is it Useful?
- When you have an external server or device on the network that needs to connect directly to a service inside Kubernetes.
- When you want to restrict access to your service to specific predefined IPs.
- When you donâ€™t need a LoadBalancer or donâ€™t want to use one.
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:stable
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  externalIPs:
  - 192.168.1.100
```
### How to Access the Service?
* If you are on a network that has access to the IP 192.168.1.100, you can send a request using a browser or curl:`http://192.168.1.100`
* If everything is set up correctly, the default Nginx page will be displayed.

### Where is External IP Good and Where is it Not?
Good For:
- When you have a specific IP that needs to connect directly to a Kubernetes service.
- When you have a pre-defined network infrastructure with specific IPs.

Limitations:
- External IP is usually not suitable for cloud environments. In the cloud, itâ€™s better to use LoadBalancer or Ingress.
- Managing External IPs can be challenging in complex environments because Kubernetes does not have full control over those IPs.

#### Summary
- External IP allows you to expose a service inside Kubernetes through a specific IP from outside the cluster.
- This method is mainly used for internal networks or specific infrastructures.
- For cloud or public environments, itâ€™s better to use LoadBalancer or Ingress.


